{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56e0039f6912e8e1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Plan of Action:\n",
    "    1. Use starter pack to generate questions to see how good it is at doing it.\n",
    "    2. If it is bad at it, we will come back and write our own question generator in the future, but we will use it for now.\n",
    "    3. Start the report generation task\n",
    "    4. Sample ideas include: Using NLP models to \"average out\" the repetitive questions for less API usage. Have predetermined categories for types of questions. Each category must be answered in the report. Some examples of category include but are not limited to, author bias, fact cross checking, author reputation, general question asking related to the topic at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe05c12d07844d94",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This block of code reads the 2024 question document and filters out any questions not rated as '4'. Prints the output to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a168c31c4f5fa45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T13:21:22.267037Z",
     "start_time": "2025-05-28T13:21:22.261377Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Assessment</th>\n",
       "      <th>Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clueweb22-en0030-87-05450</td>\n",
       "      <td>3</td>\n",
       "      <td>What are the qualifications of the creators of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clueweb22-en0030-87-05450</td>\n",
       "      <td>3</td>\n",
       "      <td>What is Anne Lise Marstrand-Jørgensen's expert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clueweb22-en0030-87-05450</td>\n",
       "      <td>3</td>\n",
       "      <td>Does the Danish public service broadcaster DR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clueweb22-en0030-87-05450</td>\n",
       "      <td>3</td>\n",
       "      <td>What evidence supports the claim that the show...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clueweb22-en0030-87-05450</td>\n",
       "      <td>3</td>\n",
       "      <td>What is the broader context of Danish children...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Article Assessment  \\\n",
       "0  clueweb22-en0030-87-05450          3   \n",
       "1  clueweb22-en0030-87-05450          3   \n",
       "2  clueweb22-en0030-87-05450          3   \n",
       "3  clueweb22-en0030-87-05450          3   \n",
       "4  clueweb22-en0030-87-05450          3   \n",
       "\n",
       "                                            Question  \n",
       "0  What are the qualifications of the creators of...  \n",
       "1  What is Anne Lise Marstrand-Jørgensen's expert...  \n",
       "2  Does the Danish public service broadcaster DR ...  \n",
       "3  What evidence supports the claim that the show...  \n",
       "4  What is the broader context of Danish children...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Specify the path to the text file\n",
    "file_path = '2024-question-assessment.txt'\n",
    "\n",
    "array = []\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        line = line.split(\"\\t\")\n",
    "        if (line[5] == \"4\" or line[5] == \"3\"):\n",
    "            array.append(line)\n",
    "            \n",
    "        \n",
    "dataFrame = pd.DataFrame(array)\n",
    "dataFrame.columns = [\"AID\", \"Article\", \"RID\", \"Model\", \"Order\", \"Assessment\", \"Useless\", \"Question\"]\n",
    "dataFrame.drop(columns=[\"AID\", \"Model\", \"RID\", \"Useless\", \"Order\"], inplace=True)\n",
    "\n",
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fe56ffe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T15:09:07.500893Z",
     "start_time": "2025-05-28T15:09:07.486688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>URL-hash</th>\n",
       "      <th>Language</th>\n",
       "      <th>ClueWeb22-ID</th>\n",
       "      <th>Clean-Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.dailymail.co.uk/news/article-10130...</td>\n",
       "      <td>1F1D55AC16DCD50B1560DE585165466D</td>\n",
       "      <td>en</td>\n",
       "      <td>clueweb22-en0032-91-05114</td>\n",
       "      <td>Japan's Princess Mako marries commoner, loses ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.nytimes.com/2021/08/26/opinion/afg...</td>\n",
       "      <td>4CC82FB7D4CB6DE296C887E0F7F82C57</td>\n",
       "      <td>en</td>\n",
       "      <td>clueweb22-en0027-70-17775</td>\n",
       "      <td>Opinion | Let’s Not Pretend That the Way We Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.politicshome.com/thehouse/article/...</td>\n",
       "      <td>357F722430ABDA02F9757BD8E4DF0CAA</td>\n",
       "      <td>en</td>\n",
       "      <td>clueweb22-en0032-18-01494</td>\n",
       "      <td>No longer can China’s atrocities against the U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://medicaladvise.org/clinical-trials-rese...</td>\n",
       "      <td>D0823CAF7F01DCC0D8112D527D936B86</td>\n",
       "      <td>en</td>\n",
       "      <td>clueweb22-en0012-53-13803</td>\n",
       "      <td>How does molnupiravir work? - Medical Advise\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.euronews.com/2021/12/10/mexico-tru...</td>\n",
       "      <td>C623D58493D0F372CC5E56F59BD20611</td>\n",
       "      <td>en</td>\n",
       "      <td>clueweb22-en0002-69-11564</td>\n",
       "      <td>Mexico truck crash: Dozens killed after lorry ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  \\\n",
       "0  https://www.dailymail.co.uk/news/article-10130...   \n",
       "1  https://www.nytimes.com/2021/08/26/opinion/afg...   \n",
       "2  https://www.politicshome.com/thehouse/article/...   \n",
       "3  https://medicaladvise.org/clinical-trials-rese...   \n",
       "4  https://www.euronews.com/2021/12/10/mexico-tru...   \n",
       "\n",
       "                           URL-hash Language               ClueWeb22-ID  \\\n",
       "0  1F1D55AC16DCD50B1560DE585165466D       en  clueweb22-en0032-91-05114   \n",
       "1  4CC82FB7D4CB6DE296C887E0F7F82C57       en  clueweb22-en0027-70-17775   \n",
       "2  357F722430ABDA02F9757BD8E4DF0CAA       en  clueweb22-en0032-18-01494   \n",
       "3  D0823CAF7F01DCC0D8112D527D936B86       en  clueweb22-en0012-53-13803   \n",
       "4  C623D58493D0F372CC5E56F59BD20611       en  clueweb22-en0002-69-11564   \n",
       "\n",
       "                                          Clean-Text  \n",
       "0  Japan's Princess Mako marries commoner, loses ...  \n",
       "1  Opinion | Let’s Not Pretend That the Way We Wi...  \n",
       "2  No longer can China’s atrocities against the U...  \n",
       "3  How does molnupiravir work? - Medical Advise\\n...  \n",
       "4  Mexico truck crash: Dozens killed after lorry ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json \n",
    "\n",
    "# Specify the path to the text file\n",
    "file_path = '../trec-2024-lateral-reading-task2-baseline-documents.json'\n",
    "\n",
    "f = open(file_path)\n",
    "data = json.load(f)\n",
    "articles_df = pd.DataFrame.from_dict(data)\n",
    "articles_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95b85cc2af186e4b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 236/236 [23:14<00:00,  5.91s/it]\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize client properly\n",
    "client = OpenAI(api_key=api_key)\n",
    "qArray = [row[7] for row in array]  # Adjust if needed\n",
    "\n",
    "def format_prompt(qs):\n",
    "    categories = [\n",
    "        \"Author Bias\",\n",
    "        \"Factual Query\",\n",
    "        \"Author Reputation\",\n",
    "        \"Publication Reputation\"\n",
    "    ]\n",
    "    prompt = f\"Classify each of the following questions into one of these categories per line: {', '.join(categories)}.\\n\\n\"\n",
    "    prompt_tail = (\n",
    "        '\\nReturn the result as plain CSV with no extra text. Each row should have two columns: '\n",
    "        '\"Question\" and \"Category\". Format like this:\\n\\n'\n",
    "        '\"Question\",\"Category\"\\n'\n",
    "        '\"Example question here?\",\"Author Bias\"\\n')\n",
    "    for i, q in enumerate(qs, 1):\n",
    "        prompt += f\"{i}. {q.strip()}\\n\"\n",
    "    prompt += prompt_tail\n",
    "    return prompt\n",
    "\n",
    "# Batch the questions to avoid exceeding token/context limits\n",
    "batch_size = 20  # Adjust as needed for your model/context\n",
    "prompts = [format_prompt(qArray[i:i+batch_size]) for i in range(0, len(qArray), batch_size)]\n",
    "outputs = []\n",
    "\n",
    "for prompt_text in tqdm(prompts, desc=\"Processing batches\"):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt_text}],\n",
    "        temperature=0\n",
    "    )\n",
    "    outputs.append(response.choices[0].message.content)\n",
    "    time.sleep(0.2) \n",
    "# Save all outputs to a single CSV file\n",
    "with open(\"output.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    header_written = False\n",
    "    for output in outputs:\n",
    "        lines = output.strip().splitlines()\n",
    "        if not header_written:\n",
    "            f.write(lines[0] + \"\\n\")  # Write header\n",
    "            header_written = True\n",
    "        for line in lines[1:]:\n",
    "            f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0bc98ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     46\u001b[39m dataset = TextDataset(\u001b[38;5;28mlist\u001b[39m(Q_train), \u001b[38;5;28mlist\u001b[39m(c_train))\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Define training arguments\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m training_args = \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./results\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./logs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mno\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     56\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Set up Trainer API to handle training loop\u001b[39;00m\n\u001b[32m     59\u001b[39m trainer = Trainer(\n\u001b[32m     60\u001b[39m     model=model,\n\u001b[32m     61\u001b[39m     args=training_args,\n\u001b[32m     62\u001b[39m     train_dataset=dataset\n\u001b[32m     63\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:131\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, include_for_metrics, eval_do_concat_batches, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start, use_liger_kernel, eval_use_gather_object, average_tokens_across_devices)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mvand\\Desktop\\TREC2025\\.venv\\Lib\\site-packages\\transformers\\training_args.py:1738\u001b[39m, in \u001b[36mTrainingArguments.__post_init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1736\u001b[39m \u001b[38;5;66;03m# Initialize device before we proceed\u001b[39;00m\n\u001b[32m   1737\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_torch_available():\n\u001b[32m-> \u001b[39m\u001b[32m1738\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m   1740\u001b[39m \u001b[38;5;66;03m# Disable average tokens when using single device\u001b[39;00m\n\u001b[32m   1741\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.average_tokens_across_devices:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mvand\\Desktop\\TREC2025\\.venv\\Lib\\site-packages\\transformers\\training_args.py:2268\u001b[39m, in \u001b[36mTrainingArguments.device\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2264\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2265\u001b[39m \u001b[33;03mThe device used by this process.\u001b[39;00m\n\u001b[32m   2266\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2267\u001b[39m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[33m\"\u001b[39m\u001b[33mtorch\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2268\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setup_devices\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mvand\\Desktop\\TREC2025\\.venv\\Lib\\site-packages\\transformers\\utils\\generic.py:67\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, obj, objtype)\u001b[39m\n\u001b[32m     65\u001b[39m cached = \u001b[38;5;28mgetattr\u001b[39m(obj, attr, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     cached = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(obj, attr, cached)\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cached\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mvand\\Desktop\\TREC2025\\.venv\\Lib\\site-packages\\transformers\\training_args.py:2138\u001b[39m, in \u001b[36mTrainingArguments._setup_devices\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[32m   2137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[32m-> \u001b[39m\u001b[32m2138\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m   2139\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2140\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease run `pip install transformers[torch]` or `pip install \u001b[39m\u001b[33m'\u001b[39m\u001b[33maccelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2141\u001b[39m         )\n\u001b[32m   2142\u001b[39m \u001b[38;5;66;03m# We delay the init of `PartialState` to the end for clarity\u001b[39;00m\n\u001b[32m   2143\u001b[39m accelerator_state_kwargs = {\u001b[33m\"\u001b[39m\u001b[33menabled\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33muse_configured_state\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n",
      "\u001b[31mImportError\u001b[39m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "df1 = pd.read_csv(\"output.csv\", header=None, names=[\"Question\", \"Category\"])\n",
    "\n",
    "col1 = df1.iloc[:, 0].to_numpy()\n",
    "col2 = df1.iloc[:, 1].to_numpy()\n",
    "\n",
    "\n",
    "Q_train, Q_test, c_train, c_test = train_test_split(col1, col2, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "labels = [0, 1, 2, 3]  # You define your label mapping\n",
    "\n",
    "# Define label names for readability (optional)\n",
    "label_names = [\"Author Bias\",\n",
    "        \"Factual Query\",\n",
    "        \"Author Reputation\",\n",
    "        \"Publication Reputation\"]\n",
    "\n",
    "# Load tokenizer and model with built-in classification head\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(label_names))\n",
    "\n",
    "# Define custom Dataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, Q_train, c_train):\n",
    "        self.encodings = tokenizer(Q_train, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "        le = LabelEncoder()\n",
    "        c_train_encoded = le.fit_transform(c_train) \n",
    "        self.labels = torch.tensor(c_train_encoded)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "# Prepare dataset\n",
    "dataset = TextDataset(list(Q_train), list(c_train))\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"no\"\n",
    ")\n",
    "\n",
    "# Set up Trainer API to handle training loop\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# Predict on new texts\n",
    "test_encodings = tokenizer(Q_test, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "outputs = model(**test_encodings)\n",
    "predictions = torch.argmax(outputs.logits, dim=1)\n",
    "for text, label_idx in zip(Q_test, predictions):\n",
    "    print(f\"{text} -> {label_names[label_idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8129ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
